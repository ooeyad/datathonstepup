{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "newshack_kaggle2 (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3.5",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "collapsed": true,
        "id": "_2qxcnWknnpk",
        "colab_type": "text"
      },
      "source": [
        "# Import the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d6fb32fd69316596e236eab5fb8cf77c848508c3",
        "id": "CkKZaRnDnnqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn as sk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Model\n",
        "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding,GRU\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import gensim\n",
        "from gensim.models import LdaModel\n",
        "from gensim import models, corpora, similarities\n",
        "import re\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import time\n",
        "from nltk import FreqDist\n",
        "from scipy.stats import entropy\n",
        "from subprocess import check_output\n",
        "import io\n",
        "import matplotlib\n",
        "from zipfile import ZipFile\n",
        "from tqdm import tqdm\n",
        "from bs4 import BeautifulSoup\n",
        "from keras import backend as K\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from sklearn.metrics import f1_score\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "%matplotlib inline\n",
        "\n",
        "matplotlib.style.use('ggplot')\n",
        "sns.set_style(\"darkgrid\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omw7cbMf8RAA",
        "colab_type": "code",
        "outputId": "c47b4e24-9414-4744-d508-817e42630b75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "# Load trained fasttext embedding 300 Vector dimension\n",
        " !wget 'https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip'\n",
        "#Load news data from amazonaws for propaganda-datathon\n",
        " !wget 'https://s3.us-east-2.amazonaws.com/propaganda-datathon/dataset/datasets-v5.zip'\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-17 08:26:51--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.6.166, 104.20.22.166, 2606:4700:10::6814:6a6, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.6.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1523785255 (1.4G) [application/zip]\n",
            "Saving to: ‘crawl-300d-2M.vec.zip.1’\n",
            "\n",
            "crawl-300d-2M.vec.z 100%[===================>]   1.42G  11.8MB/s    in 2m 5s   \n",
            "\n",
            "2020-02-17 08:28:57 (11.7 MB/s) - ‘crawl-300d-2M.vec.zip.1’ saved [1523785255/1523785255]\n",
            "\n",
            "--2020-02-17 08:28:59--  https://s3.us-east-2.amazonaws.com/propaganda-datathon/dataset/datasets-v5.zip\n",
            "Resolving s3.us-east-2.amazonaws.com (s3.us-east-2.amazonaws.com)... 52.219.84.186\n",
            "Connecting to s3.us-east-2.amazonaws.com (s3.us-east-2.amazonaws.com)|52.219.84.186|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 50012761 (48M) [application/zip]\n",
            "Saving to: ‘datasets-v5.zip’\n",
            "\n",
            "datasets-v5.zip     100%[===================>]  47.70M  12.3MB/s    in 4.9s    \n",
            "\n",
            "2020-02-17 08:29:05 (9.79 MB/s) - ‘datasets-v5.zip’ saved [50012761/50012761]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtQi8PvATwCO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_words = 100000 \n",
        "max_len = 500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vy-na28jQ8RN",
        "colab_type": "text"
      },
      "source": [
        "# Load and prepare data from the folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0sBBklnnnvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "import os\n",
        "\n",
        "class EmbedLoader:\n",
        "    \n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def get_embedding(self, embedding_file, embed_size):\n",
        "        embedding_index = {}\n",
        "        with open(embedding_file, encoding='utf8') as f:\n",
        "            for line in f:\n",
        "                values = line.rstrip().rsplit(' ')\n",
        "                # word = ' '.join(values[:-embed_size])\n",
        "                # coefs = np.asarray(values[-embed_size:], dtype='float32')\n",
        "                word = values[0]\n",
        "                coefs = np.asarray(values[1:], dtype='float32')\n",
        "                embedding_index[word] = coefs\n",
        "        f.close()\n",
        "\n",
        "        return embedding_index\n",
        "\n",
        "    def get_embedding2(self, embedding_file):\n",
        "        embeddings_index = dict(self._get_coefs(*o.rstrip().split(' ')) for o in open(embedding_file))\n",
        "        return embeddings_index\n",
        "\n",
        "    def _get_coefs(self,word, *arr):\n",
        "        return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "    def get_embedding_matrix(self, embedding_index, word_index, embed_size, max_features):\n",
        "\n",
        "        print(\"size word index: \" , len(word_index))\n",
        "        vocab_size = min(len(word_index), max_features) + 1\n",
        "        embedding_matrix = np.zeros((vocab_size, embed_size))\n",
        "\n",
        "        print(\"embedding_matrix shape: \", embedding_matrix.shape)\n",
        "\n",
        "        for word, index in word_index.items():\n",
        "            if index >= vocab_size:\n",
        "                continue\n",
        "            embedding_vector = embedding_index.get(word)\n",
        "            if embedding_vector is not None:\n",
        "                embedding_matrix[index] = embedding_vector\n",
        "\n",
        "        return embedding_matrix, vocab_size\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuK3F95ZVDsh",
        "colab_type": "text"
      },
      "source": [
        "Define a swish activation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJg-PGAZlClU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Swish(Activation):\n",
        "    \n",
        "    def __init__(self, activation, **kwargs):\n",
        "        super(Swish, self).__init__(activation, **kwargs)\n",
        "        self.__name__ = 'swish'\n",
        "\n",
        "def swish(x):\n",
        "    return (K.sigmoid(x) * x)\n",
        "\n",
        "get_custom_objects().update({'swish': Swish(swish)})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEyouMWzQg6S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data(data_path):\n",
        "  # Create a ZipFile Object and load sample.zip in it\n",
        "  with ZipFile(data_path+\"/\"+\"datasets-v5.zip\", \"r\") as zipObj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zipObj.extractall()\n",
        "  f = io.open(data_path+\"/\"+\"datasets-v5/task-1/task1.train.txt\", mode=\"r\", encoding=\"utf-8\")\n",
        "  # df = pd.DataFrame(columns=[\"text\",\"article_id\",\"propaganda\"])\n",
        "  lines = f.read().split(\"\\n\")\n",
        "  x = []\n",
        "  for i in lines:\n",
        "    i = i.split(\"\\t\")\n",
        "    x.append(i)\n",
        "  df = pd.DataFrame(x, columns=[\"text\",\"article_id\",\"propaganda\"])\n",
        "  # Load nltk stopwords\n",
        "  nltk.download('stopwords')\n",
        "  # stopWords = set(stopwords.words('english'))\n",
        "  # MY STOPWORDS\n",
        "  stopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
        "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
        "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
        "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
        "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
        "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
        "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
        "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
        "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
        "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
        "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
        "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
        "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
        "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
        "            'won', \"won't\", 'wouldn', \"wouldn't\", \"no\", \"nor\",\"not\"])\n",
        "  preprocessed_text = []\n",
        "  # tqdm is for printing the status bar\n",
        "  for sentance in tqdm(df['text'].values):\n",
        "      sentance = re.sub(r\"http\\S+\", \"\", sentance)\n",
        "      sentance = BeautifulSoup(sentance, 'lxml').get_text()\n",
        "      #sentance = decontracted(sentance)\n",
        "      sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip()\n",
        "      sentance = re.sub('[^A-Za-z]+', ' ', sentance)\n",
        "      # https://gist.github.com/sebleier/554280\n",
        "      sentance = ' '.join(e.lower() for e in sentance.split() if e.lower() not in stopwords)\n",
        "      preprocessed_text.append(sentance.strip())\n",
        "  df[\"text\"] = preprocessed_text\n",
        "  df = df.dropna()\n",
        "  df['length'] = [len(text) for text in df['text']]\n",
        "  df = df[df.length < 40000]\n",
        "  X = df.text\n",
        "  Y = df.propaganda\n",
        "  le = LabelEncoder()\n",
        "  Y = le.fit_transform(Y)\n",
        "  Y = Y.reshape(-1,1)\n",
        "  X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.15)\n",
        "  X_all =  pd.concat([X_train, X_test], ignore_index=True)\n",
        "  tok = Tokenizer(num_words=max_words)\n",
        "  tok.fit_on_texts(X_all)\n",
        "  sequences = tok.texts_to_sequences(X_train)\n",
        "  sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)\n",
        "  \n",
        "  # extract and load the embedding file\n",
        "  with ZipFile('crawl-300d-2M.vec.zip', 'r') as zip:\n",
        "    zip.extract('crawl-300d-2M.vec')\n",
        "  embed_loader = EmbedLoader()\n",
        "  embedding_index = embed_loader.get_embedding2('crawl-300d-2M.vec')\n",
        "  embedding_matrix, vocab_size = embed_loader.get_embedding_matrix(embedding_index, tok.word_index,300, max_words)\n",
        "  return embedding_matrix, vocab_size,X_train,X_test,Y_train,Y_test\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3WitF6nWFzx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "949a7fc1-0cb1-4a3f-af19-93cc790ad423"
      },
      "source": [
        "embedding_matrix ,vocab_size ,X_train,X_test,Y_train,Y_test =  prepare_data(\"/content\")"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 64/35994 [00:00<00:56, 639.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 35994/35994 [00:44<00:00, 817.23it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "size word index:  162019\n",
            "embedding_matrix shape:  (100001, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "ad8706caa7a447fb49b44919fd109129e4082a93",
        "id": "-GZk7ZQnnnv3",
        "colab_type": "text"
      },
      "source": [
        "### RNN\n",
        "Define the RNN structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "78fff25b8be1de575bff071a2027f3dd2b11b911",
        "id": "4ANLzx67nnv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def RNN():\n",
        "    inputs = Input(name='inputs',shape=[max_len])\n",
        "    embed_size = 300\n",
        "    emb_layer = Embedding(vocab_size, embed_size, weights=[embedding_matrix], trainable=False, name='embedding_1')(inputs)\n",
        "    layer = emb_layer\n",
        "    layer = LSTM(256,return_sequences = True)(layer)\n",
        "    layer = LSTM(128)(layer)\n",
        "    layer = Dense(256,name='FC1')(layer)\n",
        "    layer = Activation('swish')(layer)\n",
        "    layer = Dropout(0.25)(layer)\n",
        "    layer = Dense(1,name='out_layer')(layer)\n",
        "    layer = Activation('sigmoid')(layer)\n",
        "    model = Model(inputs=inputs,outputs=layer)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "9d7c489e32bff6d12b8c08c07a91e9ba5d302e0e",
        "id": "cpWni9_SnnwF",
        "colab_type": "text"
      },
      "source": [
        "Call the function and compile the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "a0ede32d4127e8b4990fd74fe97fadef9e565d17",
        "id": "hICeDH_TnnwI",
        "colab_type": "code",
        "outputId": "7b2c2256-513d-4c6d-87b9-c845f2f5da55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        }
      },
      "source": [
        "model = RNN()\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 500, 300)          30000300  \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 500, 256)          570368    \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 128)               197120    \n",
            "_________________________________________________________________\n",
            "FC1 (Dense)                  (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "out_layer (Dense)            (None, 1)                 257       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 30,801,069\n",
            "Trainable params: 800,769\n",
            "Non-trainable params: 30,000,300\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "bc2e0a3ec50d14c790b82d66f9255456ec6a69da",
        "id": "l9PW-SYDnnwR",
        "colab_type": "text"
      },
      "source": [
        "Fit on the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dR2v5sy-gEH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss',\n",
        "                          min_delta=0,\n",
        "                          patience=2,\n",
        "                          verbose=2, mode='auto')\n",
        "checkpointer = ModelCheckpoint(filepath='model_check.hdf5', verbose=1, monitor='val_loss', save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "98f6d6318352420ea49c532cda158f715f940f4b",
        "id": "DBijyx2YnnwT",
        "colab_type": "code",
        "outputId": "9752536d-47f6-4813-ced4-2a46e33e384e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "model.fit(sequences_matrix,Y_train,batch_size=128,epochs=10,\n",
        "          validation_split=0.2,callbacks=[early_stopping, checkpointer ])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 24472 samples, validate on 6119 samples\n",
            "Epoch 1/10\n",
            "24448/24472 [============================>.] - ETA: 1s - loss: 0.3566 - acc: 0.8876 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XjtCg53GDPb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load best score\n",
        "model.load_weights('model_check.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "448ab38c2f804e47df48eb45385393aaec168032",
        "id": "VXfEEfPZnnwc",
        "colab_type": "text"
      },
      "source": [
        "The model performs well on the validation set and this configuration is chosen as the final model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "ccca7839445a7d663ee7bc425a16e247df3e0e5b",
        "id": "0e79nmGWnnwf",
        "colab_type": "text"
      },
      "source": [
        "Process the test set data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "80036135a11387d952becaf2fecf653a65c02328",
        "id": "LmwjVX1vnnwk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sequences = tok.texts_to_sequences(X_test)\n",
        "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "0b60d7d2bcc0aabf77c8c8766c59f8d73cd34547",
        "id": "mKGilUg7nnwv",
        "colab_type": "text"
      },
      "source": [
        "Evaluate the model on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "0db183049b59d96388812a98efedfc865b7cc141",
        "id": "2eBCkD9Vnnw4",
        "colab_type": "code",
        "outputId": "f2ef12dc-f7bd-48fa-b55e-27d613646b54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "accr = model.evaluate(test_sequences_matrix,Y_test)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5399/5399 [==============================] - 47s 9ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS2bFMdOnnxC",
        "colab_type": "code",
        "outputId": "d59e3f13-c7fb-41b8-c530-8806625c02a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "accr"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.16680728948145007, 0.9383219115092459]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJmKhXfEnnxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(test_sequences_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXvpAkQunnxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(y_pred)):\n",
        "    if y_pred[i] < 0.4:\n",
        "        y_pred[i] = 0\n",
        "    else:\n",
        "        y_pred[i] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX7AEkbzrk7B",
        "colab_type": "code",
        "outputId": "6aa18e36-0bf5-41ed-88ac-d5c93dd4feaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "from sklearn.metrics import precision_score,recall_score\n",
        "print ('F1 score:', f1_score(Y_test, y_pred,average='macro'))\n",
        "print ('Recall:', recall_score(Y_test, y_pred,average='macro'))\n",
        "print ('Precision:', precision_score(Y_test, y_pred,average='macro'))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score: 0.8449361355624079\n",
            "Recall: 0.8599708709545095\n",
            "Precision: 0.831610708659889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MEroJPhnnxm",
        "colab_type": "code",
        "outputId": "1d81ff98-02da-4053-9806-7b9b317bd056",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.metrics import f1_score, fbeta_score\n",
        "f1_score(Y_test, y_pred, average='macro')"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8665808513002511"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_VXnhsYT2t5",
        "colab_type": "code",
        "outputId": "fb82b861-c39f-4a0b-e489-750c8fc423b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "\n",
        "f = io.open(\"task1.test.txt\", mode=\"r\", encoding=\"utf-8\")\n",
        "df = pd.DataFrame(columns=[\"text\",\"article_id\",\"propaganda\"])\n",
        "lines = f.read().split(\"\\n\")\n",
        "x = []\n",
        "for i in lines:\n",
        "    i = i.split(\"\\t\")\n",
        "    x.append(i)\n",
        "df = pd.DataFrame(x, columns=[\"text\",\"article_id\",\"propaganda\"])\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>article_id</th>\n",
              "      <th>propaganda</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Chicago police are seeking the public’s help i...</td>\n",
              "      <td>100013</td>\n",
              "      <td>?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Moment of silence at Palestine Pavilion during...</td>\n",
              "      <td>100015</td>\n",
              "      <td>?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Organization of Islamic Cooperation (OIC) ...</td>\n",
              "      <td>100024</td>\n",
              "      <td>?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The chairman of the House Oversight and Govern...</td>\n",
              "      <td>100031</td>\n",
              "      <td>?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A judge in the United Kingdom has sentenced a ...</td>\n",
              "      <td>100040</td>\n",
              "      <td>?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text article_id propaganda\n",
              "0  Chicago police are seeking the public’s help i...     100013          ?\n",
              "1  Moment of silence at Palestine Pavilion during...     100015          ?\n",
              "2  The Organization of Islamic Cooperation (OIC) ...     100024          ?\n",
              "3  The chairman of the House Oversight and Govern...     100031          ?\n",
              "4  A judge in the United Kingdom has sentenced a ...     100040          ?"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 246
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuK5qOJ5YTIk",
        "colab_type": "code",
        "outputId": "46a161aa-9dd6-48d9-921c-5da7fa24dc59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "preprocessed_text = []\n",
        "# tqdm is for printing the status bar\n",
        "for sentance in tqdm(df['text'].values):\n",
        "    sentance = re.sub(r\"http\\S+\", \"\", sentance)\n",
        "    sentance = BeautifulSoup(sentance, 'lxml').get_text()\n",
        "    #sentance = decontracted(sentance)\n",
        "    sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip()\n",
        "    sentance = re.sub('[^A-Za-z]+', ' ', sentance)\n",
        "    # https://gist.github.com/sebleier/554280\n",
        "    sentance = ' '.join(e.lower() for e in sentance.split() if e.lower() not in stopwords)\n",
        "    preprocessed_text.append(sentance.strip())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10159/10159 [00:13<00:00, 736.32it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1u3zUc_YhDT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[\"text\"] = preprocessed_text\n",
        "df.head()\n",
        "df = df.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a96pMXSIYj7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u77kRdFIYmiy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "article_id = df.article_id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjxpNGNRY2Gm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences = tok.texts_to_sequences(X)\n",
        "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUW8ZNtOY8rK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(sequences_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcfCCys0ZbyI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(y_pred)):\n",
        "    if y_pred[i] < 0.4:\n",
        "        y_pred[i] = 0\n",
        "    else:\n",
        "        y_pred[i] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dVK356gdsDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = []\n",
        "for i in range(len(y_pred)):\n",
        "  preds.append(int(y_pred[i][0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mYejb_xZdtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_submission = pd.DataFrame(\n",
        "    {'article_id': article_id,\n",
        "     'propaganda/non-propaganda': preds\n",
        "    })"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}